{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMG3W2YHmagh5MgT6G3eVwW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evansmakori/Bankruptcy-in-Poland/blob/main/05_1_bankruptcy_in_poland_Working_with_JSON_files_lesson_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1. Working with JSON files\n",
        "\n",
        "In this project, we'll be looking at tracking corporate bankruptcies in Poland. To do that, we'll need to get data that's been stored in a JSON file, explore it, and turn it into a DataFrame that we'll use to train our model."
      ],
      "metadata": {
        "id": "WH1_YlWRXTVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import wqet_grader\n",
        "from IPython.display import VimeoVideo\n",
        "\n",
        "wqet_grader.init(\"Project 5 Assessment\")\n"
      ],
      "metadata": {
        "id": "VTMcFoqjXUXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Data\n",
        "Open\n",
        "The first thing we need to do is access the file that contains the data we need. We've done this using multiple strategies before, but this time around, we're going to use the command line.\n",
        "\n",
        "Task 5.1.1: Open a terminal window and navigate to the directory where the data for this project is located.\n",
        "\n",
        "What's the Linux command line?\n",
        "Navigate a file system using the Linux command line.\n",
        "As we've seen in our other projects, datasets can be large or small, messy or clean, and complex or easy to understand. Regardless of how the data looks, though, it needs to be saved in a file somewhere, and when that file gets too big, we need to compress it. Compressed files are easier to store because they take up less space. If you've ever come across a ZIP file, you've worked with compressed data.\n",
        "\n",
        "The file we're using for this project is compressed, so we'll need to use a file utility called gzip to open it up."
      ],
      "metadata": {
        "id": "dU3GrpS7XYKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.1.2: In the terminal window, locate the data file for this project and decompress it."
      ],
      "metadata": {
        "id": "QoOQO9VvXato"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd data\n",
        "gzip -dfk poland-bankruptcy-data-2009.json.gz\n"
      ],
      "metadata": {
        "id": "ZqlIBH83XcGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore\n",
        "Now that we've decompressed the data, let's take a look and see what's there."
      ],
      "metadata": {
        "id": "c5gF7xzsXdpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.1.3: In the terminal window, examine the first 10 lines of poland-bankruptcy-data-2009.json."
      ],
      "metadata": {
        "id": "c-7g9VFxXfYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Does this look like any of the data structures we've seen in previous projects?"
      ],
      "metadata": {
        "id": "eqo6ORlzXkrv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.1.4: Open poland-bankruptcy-data-2009.json by opening the data folder to the left and then double-clicking on the file. ðŸ‘ˆ\n",
        "\n",
        "How is the data organized?\n",
        "\n",
        "Curly brackets? Key-value pairs? It looks similar to a Python dictionary. It's important to note that JSON is not exactly the same as a dictionary, but a lot of the same concepts apply. Let's try reading the file into a DataFrame and see what happens."
      ],
      "metadata": {
        "id": "KpnelnRRXmTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json(\"data/poland-bankruptcy-data-2009.json\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "MveVswZUXony"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmmm. It looks like something went wrong, and we're going to have to fix it. Luckily for us, there's an error message to help us figure out what's happening here:\n",
        "\n",
        "ValueError: Mixing dicts with non-Series may lead to ambiguous ordering.\n",
        "\n",
        "What should we do? That error sounds serious, but the world is big, and we can't possibly be the first people to encounter this problem. When you come across an error, copy the message into a search engine and see what comes back. You'll get lots of results. The web has lots of places to look for solutions to problems like this one, and Stack Overflow is one of the best. Click here to check out a possible solution to our problem.\n",
        "\n",
        "There are three things to look for when you're browsing through solutions on Stack Overflow.\n",
        "\n",
        "Context: A good question is specific; if you click through that link, you'll see that the person asks a specific question, gives some relevant information about their OS and hardware, and then offers the code that threw the error. That's important, because we need...\n",
        "Reproducible Code: A good question also includes enough information for you to reproduce the problem yourself. After all, the only way to make sure the solution actually applies to your situation is to see if the code in the question throws the error you're having trouble with! In this case, the person included not only the code they used to get the error, but the actual error message itself. That would be useful on its own, but since you're looking for an actual solution to your problem, you're really looking for...\n",
        "An answer: Not every question on Stack Overflow gets answered. Luckily for us, the one we've been looking at did. There's a big green check mark next to the first solution, which means that the person who asked the question thought that solution was the best one.\n",
        "Let's try it and see if it works for us too!"
      ],
      "metadata": {
        "id": "TjDVX1x4XrhT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.1.6: Using a context manager, open the file poland-bankruptcy-data-2009.json and load it as a dictionary with the variable name poland_data."
      ],
      "metadata": {
        "id": "yeEZ5vQUXs76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open file and load JSON\n",
        "with open(\"data/poland-bankruptcy-data-2009.json\", \"r\") as read_file:\n",
        "    poland_data = json.load(read_file)\n",
        "\n",
        "print(type(poland_data))"
      ],
      "metadata": {
        "id": "BbkwxokBXuE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay! Now that we've successfully opened up our dataset, let's take a look and see what's there, starting with the keys. Remember, the keys in a dictionary are categories of things in a dataset.WQU WorldQuant University Applied Data Science Lab QQQQ"
      ],
      "metadata": {
        "id": "6Jlh9X-bXv_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.1.7: Print the keys for poland_data."
      ],
      "metadata": {
        "id": "lUNm7m3CXxNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print `poland_data` keys\n",
        "poland_data.keys()"
      ],
      "metadata": {
        "id": "XzSBUi6TXyPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "schema tells us how the data is structured, metadata tells us where the data comes from, and data is the data itself.\n",
        "\n",
        "Now let's take a look at the values. Remember, the values in a dictionary are ways to describe the variable that belongs to a key."
      ],
      "metadata": {
        "id": "gBUY4wozX0UK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.1.8: Explore the values associated with the keys in poland_data. What do each of them represent? How is the information associated with the \"data\" key organized?"
      ],
      "metadata": {
        "id": "0FtfUC3TX2Ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue Exploring `poland_data`\n",
        "#poland_data[\"metadata\"]\n",
        "#poland_data[\"schema\"].keys()\n",
        "poland_data[\"data\"][0]"
      ],
      "metadata": {
        "id": "87YMdUagX3BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset includes all the information we need to figure whether or not a Polish company went bankrupt in 2009. There's a bunch of features included in the dataset, each of which corresponds to some element of a company's balance sheet. You can explore the features by looking at the data dictionary. Most importantly, we also know whether or not the company went bankrupt. That's the last key-value pair.\n",
        "\n",
        "Now that we know what data we have for each company, let's take a look at how many companies there are.\n",
        "\n",
        "VimeoVideo(\"693794783\", h=\"8d333027cc\", width=600)\n",
        "\n",
        "Task 5.1.9: Calculate the number of companies included in the dataset."
      ],
      "metadata": {
        "id": "sVuogyHYX5Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate number of companies\n",
        "len(poland_data[\"data\"])"
      ],
      "metadata": {
        "id": "q-9_PIUxX7s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.1.10: Calculate the number of features associated with \"company_1\"."
      ],
      "metadata": {
        "id": "GQcJToiIX9l-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate number of features\n",
        "len(poland_data[\"data\"][0])"
      ],
      "metadata": {
        "id": "Se4C0s-JX-pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.1.11: Iterate through the companies in poland_data[\"data\"] and check that they all have the same number of features."
      ],
      "metadata": {
        "id": "99-c5upyYBDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through companies\n",
        "for item in poland_data[\"data\"]:\n",
        "    if len(item) !=66:\n",
        "        print(\"ALERT\")\n",
        ""
      ],
      "metadata": {
        "id": "T2z9qf_4YB8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.1.12: Using a context manager, open the file poland-bankruptcy-data-2009.json.gz and load it as a dictionary with the variable name poland_data_gz."
      ],
      "metadata": {
        "id": "ObOTTp2PYDu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open compressed file and load contents\n",
        "with gzip.open(\"data/poland-bankruptcy-data-2009.json.gz\", \"r\") as read_file:\n",
        "    poland_data = json.load(read_file)\n",
        "\n",
        "\n",
        "print(type(poland_data_gz))"
      ],
      "metadata": {
        "id": "mqenlHf6YE6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we now have two versions of the dataset â€” one compressed and one uncompressed â€” we need to compare them to make sure they're the same.\n",
        "\n",
        "VimeoVideo(\"693794837\", h=\"925b5e4e5a\", width=600)\n",
        "\n",
        "Task 5.1.13: Explore poland_data_gz to confirm that is contains the same data as data, in the same format."
      ],
      "metadata": {
        "id": "pKc_YOwyYG8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore `poland_data_gz`\n",
        "print(len(poland_data_gz[\"data\"]))\n",
        "print(len(poland_data_gz[\"data\"][0]))"
      ],
      "metadata": {
        "id": "d9w6oeKnYJxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.1.14: Create a DataFrame df that contains the all companies in the dataset, indexed by \"company_id\". Remember the principles of tidy data that you learned in Project 1, and make sure your DataFrame has shape (9977, 65)."
      ],
      "metadata": {
        "id": "x5Y5DY9uYLMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame().from_dict(poland_data_gz[\"data\"]).set_index(\"company_id\")\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "qN9xTzFjYMTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "mport\n",
        "Now that we have everything set up the way we need it to be, let's combine all these steps into a single function that will decompress the file, load it into a DataFrame, and return it to us as something we can use."
      ],
      "metadata": {
        "id": "XbpVqLGNYOSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.1.15: Create a wrangle function that takes the name of a compressed file as input and returns a tidy DataFrame. After you confirm that your function is working as intended, submit it to the grader."
      ],
      "metadata": {
        "id": "KQZ_B77pYPv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wrangle(filename):\n",
        "    #open compressed file and load into dict\n",
        "    with gzip.open(filename,\"r\") as f:\n",
        "        data= json.load(f)\n",
        "\n",
        "    #tunring dict into DataFrame\n",
        "    df=pd.DataFrame().from_dict(data[\"data\"]).set_index(\"company_id\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "8V3O4RjpYQ-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = wrangle(\"data/poland-bankruptcy-data-2009.json.gz\")\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "uRX5-S_zYSFJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}