{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlfJ5dhC8TyH2mkeTxotNi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evansmakori/Bankruptcy-in-Poland/blob/main/05_5_bankruptcy_in_poland_Assignment_Bankruptcy_in_Taiwan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.5. Bankruptcy in Taiwan ðŸ‡¹ðŸ‡¼"
      ],
      "metadata": {
        "id": "ddfycps9gMz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wqet_grader\n",
        "\n",
        "wqet_grader.init(\"Project 5 Assessment\")"
      ],
      "metadata": {
        "id": "WDSzI5e9gN0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries here\n",
        "import gzip\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "import ipywidgets as widgets\n",
        "import pandas as pd\n",
        "import wqet_grader\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from IPython.display import VimeoVideo\n",
        "from ipywidgets import interact\n",
        "from sklearn.metrics import (\n",
        "    ConfusionMatrixDisplay,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        ")\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from teaching_tools.widgets import ConfusionMatrixWidget"
      ],
      "metadata": {
        "id": "OO3oBOrigOzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Data\n",
        "Import\n",
        "Task 5.5.1: Load the contents of the \"data/taiwan-bankruptcy-data.json.gz\" and assign it to the variable taiwan_data.\n",
        "\n",
        "Note that taiwan_data should be a dictionary. You'll create a DataFrame in a later task.\n",
        "\n",
        "# Load data file"
      ],
      "metadata": {
        "id": "fjCkrS5ggQZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data file\n",
        "with gzip.open(\"data/taiwan-bankruptcy-data.json.gz\",\"r\") as f:\n",
        "    taiwan_data=json.load(f)\n",
        "print(type(taiwan_data))"
      ],
      "metadata": {
        "id": "_oyWuz8UgRdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.5.2: Extract the key names from taiwan_data and assign them to the variable taiwan_data_keys."
      ],
      "metadata": {
        "id": "8BUJsXIpgTT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "taiwan_data_keys = taiwan_data.keys()\n",
        "print(taiwan_data_keys)"
      ],
      "metadata": {
        "id": "yC6mYKtWgUdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.5.3: Calculate how many companies are in taiwan_data and assign the result to n_companies."
      ],
      "metadata": {
        "id": "gu84tZVWgWNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_companies = len(taiwan_data[\"observations\"])\n",
        "print(n_companies)"
      ],
      "metadata": {
        "id": "7-g-rjT7gZC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.5.4: Calculate the number of features associated with each company and assign the result to n_features."
      ],
      "metadata": {
        "id": "H1dqHdShgajV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#taiwan_data[\"metadata\"]\n",
        "#taiwan_data[\"schema\"].keys()"
      ],
      "metadata": {
        "id": "2XkEuWRKgcGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = len(taiwan_data[\"observations\"][0])\n",
        "print(n_features)"
      ],
      "metadata": {
        "id": "jpJV54XHgd18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame().from_dict(taiwan_data[\"observations\"])\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "p2NphrjEge_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in taiwan_data[\"observations\"]:\n",
        "    if len(item) !=97:\n",
        "        print(\"ALERT\")"
      ],
      "metadata": {
        "id": "CjO64sPigg9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.5.5: Create a wrangle function that takes as input the path of a compressed JSON file and returns the file's contents as a DataFrame. Be sure that the index of the DataFrame contains the ID of the companies. When your function is complete, use it to load the data into the DataFrame df."
      ],
      "metadata": {
        "id": "5d2F7qCWgi1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create wrangle function\n",
        "def wrangle(filename):\n",
        "    #open compressed file and load into dict\n",
        "    with gzip.open(filename,\"r\") as f:\n",
        "        taiwan_data= json.load(f)\n",
        "\n",
        "    #tunring dict into DataFrame\n",
        "    df=pd.DataFrame().from_dict(taiwan_data[\"observations\"]).set_index(\"id\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "V4a26Z5SgkSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = wrangle(\"data/taiwan-bankruptcy-data.json.gz\")\n",
        "print(\"df shape:\", df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "NoYqhFZJgllR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore\n",
        "Task 5.5.6: Is there any missing data in the dataset? Create a Series where the index contains the name of the columns in df and the values are the number of NaNs in each column. Assign the result to nans_by_col. Neither the Series itself nor its index require a name. WQU WorldQuant University Applied Data Science Lab QQQQ"
      ],
      "metadata": {
        "id": "IKZmhovegner"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect DataFrame\n",
        "#df.info()\n",
        "#df.isnull().sum() / len(df)\n",
        "len(df.isnull().sum())\n",
        "df.info()"
      ],
      "metadata": {
        "id": "PIaVj3CAgohp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nans_by_col = df.isnull().sum()"
      ],
      "metadata": {
        "id": "3gw15UlVEi56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nans_by_col = df.isnull().sum() / len(df)\n",
        "pd.Series(nans_by_col)\n",
        "print(\"nans_by_col shape:\", nans_by_col.shape)"
      ],
      "metadata": {
        "id": "5FllrR1Ugptq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.5.7: Is the data imbalanced? Create a bar chart that shows the normalized value counts for the column df[\"bankrupt\"]. Be sure to label your x-axis \"Bankrupt\", your y-axis \"Frequency\", and use the title \"Class Balance\"."
      ],
      "metadata": {
        "id": "W5QAznOggsTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot class balance\n",
        "df[\"bankrupt\"].value_counts(normalize=True).plot(\n",
        "    kind=\"bar\",\n",
        "    xlabel=\"Bankrupt\",\n",
        "    ylabel=\"Frequency\",\n",
        "    title=\"Class Balance\"\n",
        ")\n",
        "# Don't delete the code below ðŸ‘‡\n",
        "plt.savefig(\"images/5-5-7.png\", dpi=150)\n"
      ],
      "metadata": {
        "id": "lZAPt4amgtnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split\n",
        "Task 5.5.8: Create your feature matrix X and target vector y. Your target is \"bankrupt\"."
      ],
      "metadata": {
        "id": "_KJgqzqVgvui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"bankrupt\"\n",
        "X = df.drop(columns=target)\n",
        "y = df[target]\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)"
      ],
      "metadata": {
        "id": "Y1G4IPHLgwqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.5.9: Divide your dataset into training and test sets using a randomized split. Your test set should be 20% of your data. Be sure to set random_state to 42."
      ],
      "metadata": {
        "id": "oYfxtxMGgye6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,y, test_size=0.2, random_state=42\n",
        ")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "rUnuccwtgzcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resample\n",
        "Task 5.5.10: Create a new feature matrix X_train_over and target vector y_train_over by performing random over-sampling on the training data. Be sure to set the random_state to 42."
      ],
      "metadata": {
        "id": "izb2EWtig1RS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "over_sampler = RandomOverSampler(random_state=42)\n",
        "X_train_over, y_train_over = over_sampler.fit_resample(X_train,y_train)\n",
        "print(\"X_train_over shape:\", X_train_over.shape)\n",
        "X_train_over.head()"
      ],
      "metadata": {
        "id": "1y1SerpDg2Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Model\n",
        "Iterate\n",
        "Task 5.5.11: Create a classifier clf that can be trained on (X_train_over, y_train_over). You can use any of the predictors you've learned about in the Data Science Lab."
      ],
      "metadata": {
        "id": "drcEg1lZg374"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xai5EDVrg5mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.5.12: Perform cross-validation with your classifier using the over-sampled training data, and assign your results to cv_scores. Be sure to set the cv argument to 5."
      ],
      "metadata": {
        "id": "dZCKiN57g7zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_scores = cross_val_score(\n",
        "    clf, X_train_over, y_train_over, cv=5, n_jobs=-1\n",
        ")\n",
        "print(cv_scores)"
      ],
      "metadata": {
        "id": "2uKSw5Sfg9Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ungraded Task: Create a dictionary params with the range of hyperparameters that you want to evaluate for your classifier. If you're not sure which hyperparameters to tune, check the scikit-learn documentation for your predictor for ideas."
      ],
      "metadata": {
        "id": "Xe1B3-ekg-7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"n_estimators\": range(25, 100, 25),\n",
        "    \"max_depth\": range(10, 50, 10)\n",
        "}\n",
        "params"
      ],
      "metadata": {
        "id": "va_te_jwhAgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.5.13: Create a GridSearchCV named model that includes your classifier and hyperparameter grid. Be sure to set cv to 5, n_jobs to -1, and verbose to 1."
      ],
      "metadata": {
        "id": "PAaTxKMKhDE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GridSearchCV(\n",
        "    clf,\n",
        "    param_grid=params,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "model"
      ],
      "metadata": {
        "id": "0KAreE4ahENb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ungraded Task: Fit your model to the over-sampled training data."
      ],
      "metadata": {
        "id": "2U-2WJbVhGGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_over, y_train_over)"
      ],
      "metadata": {
        "id": "zvQWWPmjhHLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.5.14: Extract the cross-validation results from your model, and load them into a DataFrame named cv_results. Looking at the results, which set of hyperparameters led to the best performance?"
      ],
      "metadata": {
        "id": "yrOifhuehI_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results =pd.DataFrame(model.cv_results_)\n",
        "cv_results.head(5)"
      ],
      "metadata": {
        "id": "9OjBS_zxhKPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.5.15: Extract the best hyperparameters from your model and assign them to best_params."
      ],
      "metadata": {
        "id": "gVCb13DphLkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = model.best_params_\n",
        "print(best_params)"
      ],
      "metadata": {
        "id": "zhyaWZq_hMls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate\n",
        "Ungraded Task: Test the quality of your model by calculating accuracy scores for the training and test data."
      ],
      "metadata": {
        "id": "pTtqbfvIhN-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_train = model.score(X_train, y_train)\n",
        "acc_test = model.score(X_test, y_test)\n",
        "\n",
        "print(\"Model Training Accuracy:\", round(acc_train, 4))\n",
        "print(\"Model Test Accuracy:\", round(acc_test, 4))"
      ],
      "metadata": {
        "id": "b8ll6fBmhO_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.5.16: Plot a confusion matrix that shows how your model performed on your test set."
      ],
      "metadata": {
        "id": "bs1N3qOMhRJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrix\n",
        "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test);\n",
        "# Don't delete the code below ðŸ‘‡\n",
        "plt.savefig(\"images/5-5-16.png\", dpi=150)\n"
      ],
      "metadata": {
        "id": "Aig8tF4ohSrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.5.17: Generate a classification report for your model's performance on the test data and assign it to class_report."
      ],
      "metadata": {
        "id": "BToHbJsvhUo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_report = classification_report(y_test, model.predict(X_test))\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "lcf2kDDBhVmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Communicate"
      ],
      "metadata": {
        "id": "tX9y0QOGhYNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importances = model.best_estimator_"
      ],
      "metadata": {
        "id": "tmiX959NhZfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.5.18: Create a horizontal bar chart with the 10 most important features for your model. Be sure to label the x-axis \"Gini Importance\", the y-axis \"Feature\", and use the title \"Feature Importance\"."
      ],
      "metadata": {
        "id": "Qqwawdi1ha3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature names from training data\n",
        "features = X_train_over.columns\n",
        "# Extract importances from model\n",
        "importances = model.best_estimator_.named_steps[\"randomforestclassifier\"].feature_importances_\n",
        "# Create a series with feature names and importances\n",
        "feat_imp = pd.Series(importances, index=features).sort_values()\n",
        "# Plot 10 most important features\n",
        "feat_imp.tail(10).plot(kind=\"barh\")\n",
        "plt.xlabel(\"Gini Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.title(\"Feature Importance\");\n",
        "# Don't delete the code below ðŸ‘‡\n",
        "plt.savefig(\"images/5-5-17.png\", dpi=150)\n"
      ],
      "metadata": {
        "id": "uOybi7_DhcHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.5.19: Save your best-performing model to a a file named \"model-5-5.pkl\"."
      ],
      "metadata": {
        "id": "o4fP-0wfhefb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "# Save model\n",
        "with open(\"model-5-5.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model, f)"
      ],
      "metadata": {
        "id": "AkPpYTAJhhGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5.5.20: Open the file my_predictor_assignment.py. Add your wrangle function, and then create a make_predictions function that takes two arguments: data_filepath and model_filepath. Use the cell below to test your module. When you're satisfied with the result, submit it to the grader.\n",
        "\n"
      ],
      "metadata": {
        "id": "M4r5-MfGhi1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import your module\n",
        "def make_predictions(data_filepath, model_filepath):\n",
        "    # Wrangle JSON file\n",
        "    X_test = wrangle(data_filepath)\n",
        "    # Load model\n",
        "    with open(model_filepath, \"rb\") as f:\n",
        "        model = pickle.load(f)\n",
        "\n",
        "    # Generate predictions\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    # Put predictions into Series with name \"bankrupt\", and same index as X_test\n",
        "    y_test_pred = pd.Series(y_test_pred, index=X_test.index, name=\"bankrupt\")\n",
        "    return y_test_pred\n",
        "\n",
        "# Generate predictions\n",
        "y_test_pred = make_predictions(\n",
        "    data_filepath=\"data/taiwan-bankruptcy-data-test-features.json.gz\",\n",
        "    model_filepath=\"model-5-5.pkl\",\n",
        ")\n",
        "\n",
        "print(\"predictions shape:\", y_test_pred.shape)\n",
        "y_test_pred.head()"
      ],
      "metadata": {
        "id": "-2z93fb86O0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "my Predict.py file"
      ],
      "metadata": {
        "id": "_XStE1xRE--y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your masterpiece :)\n",
        "# Import libraries\n",
        "import gzip\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def wrangle(filename):\n",
        "    #open compressed file and load into dict\n",
        "    with gzip.open(filename, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    #turn dict into dataframe\n",
        "    df = pd.DataFrame().from_dict(data[\"data\"]).set_index(\"company_id\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def make_predictions(data_filepath, model_filepath):\n",
        "    # Wrangle JSON file\n",
        "    X_test = wrangle(data_filepath)\n",
        "    # Load model\n",
        "    with open(model_filepath, \"rb\") as f:\n",
        "        model = pickle.load(f)\n",
        "\n",
        "    # Generate predictions\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    # Put predictions into Series with name \"bankrupt\", and same index as X_test\n",
        "    y_test_pred = pd.Series(y_test_pred, index=X_test.index, name=\"bankrupt\")\n",
        "    return y_test_pred\n"
      ],
      "metadata": {
        "id": "cvXuDJ8QFEba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "My predictor lesson py"
      ],
      "metadata": {
        "id": "BNmBCEFKFPx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import gzip\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Add wrangle function from lesson 5.4\n",
        "def wrangle(filename):\n",
        "    #open compressed file and load into dict\n",
        "    with gzip.open(filename, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    #turn dict into dataframe\n",
        "    df = pd.DataFrame().from_dict(data[\"data\"]).set_index(\"company_id\")\n",
        "    return df\n",
        "\n",
        "\n",
        "# Add make_predictions function from lesson 5.3\n",
        "def make_predictions(data_filepath, model_filepath):\n",
        "    # Wrangle JSON file\n",
        "    X_test = wrangle(data_filepath)\n",
        "    # Load model\n",
        "    with open(model_filepath, \"rb\") as f:\n",
        "        model = pickle.load(f)\n",
        "\n",
        "    # Generate predictions\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    # Put predictions into Series with name \"bankrupt\", and same index as X_test\n",
        "    y_test_pred = pd.Series(y_test_pred, index=X_test.index, name=\"bankrupt\")\n",
        "    return y_test_pred\n"
      ],
      "metadata": {
        "id": "YoXoLvX5FUY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "XuuHZ53vE_vj"
      }
    }
  ]
}